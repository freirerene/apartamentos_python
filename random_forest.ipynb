{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('apartamentos_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's get rid of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluguel</th>\n",
       "      <th>condominio</th>\n",
       "      <th>area</th>\n",
       "      <th>bairro</th>\n",
       "      <th>quartos</th>\n",
       "      <th>banheiros</th>\n",
       "      <th>garagem</th>\n",
       "      <th>anunciante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Chácara Santo Antônio</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>quintoandar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Vila Olímpia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>quintoandar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Vila das Mercês</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>quintoandar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Vila Mascote</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>quintoandar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Saúde</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>quintoandar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aluguel  condominio  area                 bairro  quartos  banheiros  \\\n",
       "0   4700.0       750.0  82.0  Chácara Santo Antônio      2.0        2.0   \n",
       "1   3720.0       970.0  50.0           Vila Olímpia      1.0        1.0   \n",
       "2   3300.0       443.0  85.0        Vila das Mercês      2.0        2.0   \n",
       "3   1250.0       752.0  35.0           Vila Mascote      1.0        1.0   \n",
       "4   2835.0       740.0  72.0                  Saúde      3.0        2.0   \n",
       "\n",
       "   garagem   anunciante  \n",
       "0      2.0  quintoandar  \n",
       "1      0.0  quintoandar  \n",
       "2      1.0  quintoandar  \n",
       "3      1.0  quintoandar  \n",
       "4      1.0  quintoandar  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = ['aluguel', 'condominio', 'area']\n",
    "df = df[(np.abs(stats.zscore(df[con])) < 3).all(axis=1)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the model\n",
    "\n",
    "#### The simplest of applications:\n",
    "In the function below we fit a very basic, non-optimized random forest regressor to our data and make predictions on the train and test sets.\n",
    "\n",
    "We also define a function to print out the predictions' MAE.\n",
    "\n",
    "We choose the mean absolute error because the price still varies a lot and the mean squared error penalizes too much this variation -- we could very well restrict the price to a price that fits one's particular budget, but its best not to modify further the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rf(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestRegressor(n_estimators=20, random_state=1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions_train = rf.predict(X_train)\n",
    "    predictions_test = rf.predict(X_test)\n",
    "    return (predictions_train, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mae(y_test, y_train, y_p_test, y_p_train):\n",
    "    mae_train = mean_absolute_error(y_train, y_p_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_p_test)\n",
    "    spread = np.abs(mae_train - mae_test)\n",
    "    print(\"MAE train: {:0.2f}\".format(mae_train))\n",
    "    print(\"-\"*100)\n",
    "    print(\"MAE test: {:0.2f}\".format(mae_test))\n",
    "    print(\"-\"*100)\n",
    "    print(\"Spread: {:0.2f}\".format(spread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 423.35\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 998.22\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 574.87\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(['aluguel', 'bairro', 'anunciante'], axis=1)\n",
    "y = df['aluguel']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "\n",
    "predictions_train, predictions_test = simple_rf(X_train, X_test, y_train, y_test)\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237.794132922796"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the model is strongly overfitting. But at least it beat the barests of benchmarks: the MAE is way below the mean absolute deviation.\n",
    "\n",
    "#### With smaller area:\n",
    "\n",
    "Like in the linear regression model, we restrict the apartaments by the area: only areas below 200 m^2 are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 390.16\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 883.83\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 493.67\n"
     ]
    }
   ],
   "source": [
    "smaller = df[df['area'] <= 200]\n",
    "\n",
    "x = smaller.drop(['aluguel', 'bairro', 'anunciante'], axis=1)\n",
    "y = smaller['aluguel']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "predictions_train, predictions_test = simple_rf(X_train, X_test, y_train, y_test)\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the target as the total price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 815.31\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 1013.56\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 198.25\n"
     ]
    }
   ],
   "source": [
    "smaller = df[df['area'] <= 200]\n",
    "\n",
    "x = smaller.drop(['aluguel', 'bairro', 'anunciante', 'condominio'], axis=1)\n",
    "y = smaller['aluguel'] + smaller['condominio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "predictions_train, predictions_test = simple_rf(X_train, X_test, y_train, y_test)\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the linear regression model this was the best model we found. Let's compare the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MAE: 1078.33\n"
     ]
    }
   ],
   "source": [
    "features = ['area', 'quartos']\n",
    "x = smaller[features]\n",
    "y = smaller['aluguel'] + smaller['condominio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "prediction_test_lr = lr.predict(X_test)\n",
    "predictions_train_lr = lr.predict(X_train)\n",
    "\n",
    "print(\"Linear regression MAE: {:0.2f}\".format(mean_absolute_error(y_test, prediction_test_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even though our model is not yet optimized -- is strongly overfitting, we're only using `20` trees, and so on -- we were able to reach a (if only slightly) better result with it than with our linear regression.\n",
    "\n",
    "This goes to show that random forests (and models that involve trees, like xgboost) are much better, because they don't require a linear relationship between the variables. The downside is that they are much slower -- this isn't really an issue here, but with larger datasets it can be quite cumbersome.\n",
    "\n",
    "#### With the neighborhoods\n",
    "\n",
    "Now, as a least tweak, let's see what is the result if we include the neighborhoods as variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.get_dummies(df, columns=['bairro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 293.67\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 749.83\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 456.16\n"
     ]
    }
   ],
   "source": [
    "smaller_b = df_b[df_b['area'] <= 200]\n",
    "\n",
    "x = smaller_b.drop(['aluguel', 'anunciante'], axis=1)\n",
    "y = smaller_b['aluguel']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "predictions_train, predictions_test = simple_rf(X_train, X_test, y_train, y_test)\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs a bit better, and the overfitting is not much different from the one with smaller area but with no neighborhoods as variables.\n",
    "\n",
    "With the neighborhoods targeting the total price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 413.55\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 812.13\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 398.58\n"
     ]
    }
   ],
   "source": [
    "smaller_b = df_b[df_b['area'] <= 200]\n",
    "\n",
    "x = smaller_b.drop(['aluguel', 'anunciante', 'condominio'], axis=1)\n",
    "y = smaller_b['aluguel'] + smaller_b['condominio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "predictions_train, predictions_test = simple_rf(X_train, X_test, y_train, y_test)\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing only the appraoch of targeting the total price we achieve the best result here, considering also the neighborhoods.\n",
    "\n",
    "There's no escaping it: the `condominio` does relates with the `aluguel` somehow, so excluding it as an independent variable will affect our results. But in the end its the total price we're interested in knowing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection\n",
    "\n",
    "We'll optimize our model in two steps: first we'll select the features that are most relevant to the regression and then we'll go on tuning the hyperparameters.\n",
    "\n",
    "For feature selection we'll use `RFECV` from `sklearn.feature_selection`: it simply does a recursive feature elimination, trying each combination, and in each combination performing a cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define again our `x` and `y` and split them between test and train sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = smaller_b.drop(['aluguel', 'anunciante', 'condominio'], axis=1)\n",
    "y = smaller_b['aluguel'] + smaller_b['condominio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we initiate the model we want (to wit, a random forest regressor), initiate the `RFECV`, using as criteria the MAE (we already explained the reason, vide supra).\n",
    "\n",
    "We get the features with the `selector.support_` selecting (as a boolean selector) the columns of `x`.\n",
    "\n",
    "Since this selection takes some time we did it on another computer and saved the results to `optimized_columns.data`. So the cell below only contains the unexecuted code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=1)\n",
    "\n",
    "selector = RFECV(rf, scoring='neg_mean_absolute_error', cv=3)\n",
    "selector.fit(x, y)\n",
    "\n",
    "optimized_columns = X_train.columns[selector.support_]\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('optimized_columns.data', 'wb') as filehandle:\n",
    "    pickle.dump(optimized_columns, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the `optimized_columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area', 'quartos', 'banheiros', 'garagem', 'bairro_Aclimação',\n",
      "       'bairro_Alto da Boa Vista', 'bairro_Alto da Lapa',\n",
      "       'bairro_Alto da Mooca', 'bairro_Alto de Pinheiros',\n",
      "       'bairro_Americanópolis',\n",
      "       ...\n",
      "       'bairro_Vila do Bosque', 'bairro_Vila do Castelo',\n",
      "       'bairro_Vila do Encontro', 'bairro_Vila dos Remédios',\n",
      "       'bairro_Várzea da Barra Funda', 'bairro_Várzea de Baixo',\n",
      "       'bairro_Água Branca', 'bairro_Água Fria', 'bairro_Água Funda',\n",
      "       'bairro_Água Rasa'],\n",
      "      dtype='object', length=453)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('optimized_columns.data', 'rb') as filehandle:\n",
    "    optimized_columns = pickle.load(filehandle)\n",
    "    \n",
    "print(optimized_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[optimized_columns]\n",
    "X_test = X_test[optimized_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 405.88\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 804.09\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 398.22\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(random_state=1)\n",
    "rf2.fit(X_train, y_train)\n",
    "predictions_train = rf2.predict(X_train)\n",
    "predictions_test = rf2.predict(X_test)\n",
    "\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters\n",
    "\n",
    "Now that we see what we can do and have a baisc benchmark, let's do some optimizations: we'll do a grid search cross validation (using `GridSearchCV`).\n",
    "\n",
    "Basically, we'll set a grid of parameters and the `GridSearchCV` method will make a cross validation using each combination.\n",
    "\n",
    "In the end we should arrive, given our initial grid, the best combination of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with the following variables: smaller areas, optimized features and target is the total price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = smaller_b[optimized_columns]\n",
    "y = smaller_b['aluguel'] + smaller_b['condominio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains the code for the grid search, but since it takes quite a while to run the code and we did it on another computer, we'll just put the code here with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap = [True, False]\n",
    "max_depth = [5, 10, 100, None]\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [2,3,5]\n",
    "max_features = ['log2', 'sqrt', 'auto']\n",
    "n_estimators = [200, 500, 1000]\n",
    "min_impurity_decrease = [0.0, 0.25, 0.5]\n",
    "\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'bootstrap': bootstrap,\n",
    "        'min_impurity_decrease': min_impurity_decrease\n",
    "       }\n",
    "\n",
    "rf = RandomForestRegressor(criterion='mae')\n",
    "rf_gridsearch = GridSearchCV(estimator=rf,\n",
    "                             param_grid=grid,\n",
    "                             scoring='neg_mean_absolute_error', \n",
    "                             cv = 3,\n",
    "                             verbose=2)\n",
    "\n",
    "rf_gridsearch.fit(x, y)\n",
    "rf_gridsearch.best_params_\n",
    "\n",
    "# This gives:\n",
    "\n",
    "# {'n_estimators': 500,\n",
    "#         'max_features': 'sqrt',\n",
    "#         'max_depth': None,\n",
    "#         'min_samples_split': 10,\n",
    "#         'min_samples_leaf': 3,\n",
    "#         'bootstrap': False,\n",
    "#         'min_impurity_decrease': 0.25\n",
    "#        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 772.70\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE test: 827.73\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spread: 55.02\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=3,\n",
    "                           max_features='sqrt',\n",
    "                           max_depth=None,\n",
    "                           bootstrap=False,\n",
    "                           min_impurity_decrease=0.25,\n",
    "                           random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions_train = rf.predict(X_train)\n",
    "predictions_test = rf.predict(X_test)\n",
    "\n",
    "print_mae(y_test, y_train, predictions_test, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even though our results were marginally worse than the non-optimized one (around R$`15` or R$`20`, depending on which results we are comparing -- optimized features/non-optimized features), we decreased the overfitting very much: it went from a spread of `398.22` to a spread of `55.02`.\n",
    "\n",
    "This is not trivial. Decision trees models are very easily overfitted -- they might just pick up the particularity of the training set and construct a sort of monster with them -- and a drastic decrease like (of about `86%`) this means our model performs better in the real world.\n",
    "\n",
    "This is much more realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A particular case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to know if the price of a particular apartament is above or below the market price for similar apartaments. \n",
    "\n",
    "A naive person will just take the mean of the price for apartaments sharing similar attributes. To make the case concrete let's say the person is evaluating an apartament in Pinheiros, of about 85 squared meters, with 2 bedrooms, 1 bathroom and 1 garage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229.0\n"
     ]
    }
   ],
   "source": [
    "df_eval = df[(df['bairro'] == 'Pinheiros') & (df['area'].between(80.0,90.0)) & (df['quartos'] == 2) & (df['banheiros'] == 1) & (df['garagem'] == 1)]\n",
    "\n",
    "y_eval = df_eval['aluguel'] + df_eval['condominio']\n",
    "\n",
    "print(y_eval.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the person uses all these attributes (not going into the strategy of using all attributes, which is not immediately obvious why it should be the best way to evaluate) to compute the mean to establish if the apartament is a good buy or not, still the mean absolute deviation is too high (compared to the MAE of our model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934.0\n"
     ]
    }
   ],
   "source": [
    "print(y_eval.mad())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a difference of a little more than `11%`.\n",
    "\n",
    "Now, to evaluate the price of such an apartament we pass it to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = pd.DataFrame({'aluguel':[np.nan], 'condominio':[np.nan], 'area':[85.0], 'bairro':['Pinheiros'], 'quartos':[2.0], 'banheiros':[1.0], 'garagem':[1.0], 'anunciante':[np.nan]})\n",
    "df_case = df.copy()\n",
    "df_case = df_case.append(case)\n",
    "df_case = pd.get_dummies(df_case, columns=['bairro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aluguel                   NaN\n",
       "condominio                NaN\n",
       "area                       85\n",
       "quartos                     2\n",
       "banheiros                   1\n",
       "                         ... \n",
       "bairro_Várzea de Baixo      0\n",
       "bairro_Água Branca          0\n",
       "bairro_Água Fria            0\n",
       "bairro_Água Funda           0\n",
       "bairro_Água Rasa            0\n",
       "Name: 0, Length: 480, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3766.22325437]\n"
     ]
    }
   ],
   "source": [
    "predict_case = rf.predict(pd.DataFrame(df_case[optimized_columns].iloc[-1]).transpose())\n",
    "print(predict_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We were able to improve not only upon the benchmark of mean plus absolute deviation (in a *very* restrict case), but also upon our previous model using linear regression.\n",
    "\n",
    "We could improve the model further, with further feature engineering and a more fine tuning with the hyperparameters (and still making combination of both). But we choose (not only because optimizing these tree models are quite time consuming) to go on to exploring the `xgboost` algorithm (on another notebook), which we already know, beforehand, that the non-optimized model gives a better MAE than the Random Forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
